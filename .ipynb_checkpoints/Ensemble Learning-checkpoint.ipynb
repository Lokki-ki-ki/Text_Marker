{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896c80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6be37af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(predictions):\n",
    "    predictions = predictions.tolist()\n",
    "    result_list=[]\n",
    "    for pred in predictions:\n",
    "        result = pred // 0.5 * 0.5\n",
    "        if (pred - result) > 0.25:\n",
    "            result += 0.5\n",
    "        if result < 1.0:\n",
    "            result = 1.0\n",
    "        if result > 5.0:\n",
    "            result = 5.0\n",
    "        result_list.append(result)\n",
    "    return result_list\n",
    "\n",
    "# Accuracy score\n",
    "def accuracy(Ypred, Ytrue):\n",
    "    Ytrue = Ytrue.tolist()\n",
    "    accurate = 0\n",
    "    for i in range(len(Ytrue)):\n",
    "        if Ytrue[i] == Ypred[i]:\n",
    "            accurate += 1\n",
    "    return accurate / len(Ytrue)\n",
    "\n",
    "# approximate accurancy rate\n",
    "def score(pred, test):\n",
    "    test = test.tolist()\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        p = pred[i]\n",
    "        t = test[i]\n",
    "        if p < t+0.5 and p > t-0.5:\n",
    "            correct += 1\n",
    "    return correct / len(test)\n",
    "\n",
    "# Total error / total number of points => by average what's the error for each point\n",
    "def error_rate(Ypred, Ytrue):\n",
    "    Ytrue=Ytrue.tolist()\n",
    "    error=0\n",
    "    for i in range(len(Ytrue)):\n",
    "        error += abs(Ytrue[i] - Ypred[i])\n",
    "    return error/len(Ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3964f",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d0f00",
   "metadata": {},
   "source": [
    "For target = vocabulary & target = cohesion:\n",
    "\n",
    "linear regressor = lr1, lr2\n",
    "\n",
    "k neighbours regressor = knn1, knn2\n",
    "\n",
    "decision tree = dt1, dt2\n",
    "\n",
    "neural network = nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "465d1cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.24.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator KNeighborsRegressor from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr1 = pickle.load(open(\"Models_sav\\lr_vocab.sav\", 'rb'))\n",
    "lr2 = pickle.load(open(\"Models_sav\\lr_cohesion.sav\", 'rb'))\n",
    "dt1 = pickle.load(open(\"Models_sav\\Decision_Tree_vocab.sav\", 'rb'))\n",
    "dt2 = pickle.load(open(\"Models_sav\\Decision_Tree_cohesion.sav\", 'rb'))\n",
    "knn1 = pickle.load(open(\"Models_sav\\knn_vocab.sav\", 'rb'))\n",
    "knn2 = pickle.load(open(\"Models_sav\\knn_cohesion.sav\", 'rb'))\n",
    "\n",
    "#nn1 = pickle.load(open(\"./neural_network_vocab.sav\", 'rb'))\n",
    "#nn2 = pickle.load(open(\"./neural_network.sav\", 'rb'))\n",
    "nn1 = tf.keras.models.load_model(\"model_deep_vocabulary\")\n",
    "nn2 = tf.keras.models.load_model(\"model_deep_cohesion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30890b",
   "metadata": {},
   "source": [
    "## 1 Predict Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8967b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Processed_Data.csv\")\n",
    "y = df['vocabulary']\n",
    "X = df.iloc[:, 7:]\n",
    "X = X.drop('corrected_text', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa1d5a",
   "metadata": {},
   "source": [
    "### 1.1 Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e9d1a",
   "metadata": {},
   "source": [
    "We use LinearRegression & DecisionTreeRegressor & KNeighboursRegressor to do a voting and check the accuracy and approximate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e25ac223",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)\n",
    "vr = VotingRegressor(\n",
    "    estimators=[('linear regressor', lr1), ('decision tree', dt1), ('KNN', knn1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472864cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "0.3997955010224949\n",
      "0.7198364008179959\n"
     ]
    }
   ],
   "source": [
    "vr.fit(X_train, y_train)\n",
    "y_pred_vr = vr.predict(X_test)\n",
    "print(accuracy(result(y_pred_vr), y_test))\n",
    "print(score(y_pred_vr, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962af4f3",
   "metadata": {},
   "source": [
    "### 1.2 AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a22e16",
   "metadata": {},
   "source": [
    "Besides, we build a AdaBoostRegressor, whose base estimator would be a DecisionTreeRegressor with optimal parameters got from the training of the single DecisionTreeRegressor dt1, to see the accuracy and approximate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b1466ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                                       max_depth=4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                                       max_depth=4))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=4)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=4)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='friedman_mse',\n",
       "                                                       max_depth=4))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1 = AdaBoostRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=4, min_samples_split=2)\n",
    ")\n",
    "ar1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b21f65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3936605316973415\n",
      "0.7188139059304703\n"
     ]
    }
   ],
   "source": [
    "y_pred_ar1 = ar1.predict(X_test)\n",
    "print(accuracy(result(y_pred_ar1), y_test))\n",
    "print(score(y_pred_ar1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "461d1020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=446857737),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=301215708),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=742893256),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=119440548),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1507096625),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=65555849),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=393976674),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=779732698),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1435535032),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=673161176),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=357373191),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=245829800),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1918532272),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=257719855),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=271989419),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1714865514),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=475971609),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=800960194),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=62196216),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=201843785),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=142713860),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=554208611),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1611955666),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1970633094),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=999725063),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=45869401),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=43395123),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=59778998),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=332892134),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=280308739),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1266023798),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=661018483),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=829500053),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=942008056),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1690470189),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=676872044),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1995236945),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=207198186),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1093995539),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1971560625),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=295603271),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=873446180),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1827564474),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=938648525),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1751571919),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1111056905),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=954789052),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=752999615),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1446059059),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=4,\n",
       "                       random_state=1435664095)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "22fd3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49290476, 1.20815133, 0.94494894, 0.97130432, 0.91712142,\n",
       "       0.87092545, 0.88733875, 0.68742175, 0.82637169, 0.73881704,\n",
       "       0.92609676, 0.87947796, 0.78771169, 0.52967959, 0.59876907,\n",
       "       0.6170221 , 0.81262245, 0.73103227, 0.96657774, 1.0788217 ,\n",
       "       0.61318263, 0.4904077 , 0.90273235, 0.57022386, 1.03170716,\n",
       "       0.85966721, 0.8399737 , 0.69625894, 0.60657307, 0.86715339,\n",
       "       1.01955672, 0.75928882, 1.1335785 , 0.50616945, 0.78731618,\n",
       "       0.60799294, 0.73090286, 0.84281938, 0.50301127, 0.83666541,\n",
       "       0.77351769, 0.76219604, 0.90017847, 0.79975564, 0.59634408,\n",
       "       1.13152158, 0.40614461, 0.80534803, 1.00067073, 0.93686305])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1.estimator_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49319204",
   "metadata": {},
   "source": [
    "### 1.3 Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45170eb",
   "metadata": {},
   "source": [
    "We also build a GradientBoostingRegressor, whose base estimator is a DecisionTreeRegressor, and see its accuracy and approximate accuracy.\n",
    "\n",
    "Need to find the best parameters for GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b836ba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'loss': 'huber'}\n",
      "0.36875762649157334\n"
     ]
    }
   ],
   "source": [
    "gbr1 = GradientBoostingRegressor(n_estimators=300)\n",
    "parameters = {\n",
    "    'loss':['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'criterion':['friedman_mse', 'squared_error', 'mse']\n",
    "}\n",
    "gs_gbr1 = GridSearchCV(gbr1, parameters)\n",
    "gs_gbr1.fit(X_train, y_train)\n",
    "print(gs_gbr1.best_params_)\n",
    "print(gs_gbr1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "62c5e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40081799591002043\n",
      "0.7075664621676891\n"
     ]
    }
   ],
   "source": [
    "gbr1_adj = GradientBoostingRegressor(\n",
    "    criterion = 'friedman_mse',\n",
    "    learning_rate = 0.1,\n",
    "    loss = 'huber',\n",
    "    n_estimators=300\n",
    ")\n",
    "gbr1_adj.fit(X_train, y_train)\n",
    "y_pred_gbr1_adj = gbr1_adj.predict(X_test)\n",
    "\n",
    "print(accuracy(result(y_pred_gbr1_adj), y_test))\n",
    "print(score(y_pred_gbr1_adj, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d124b68",
   "metadata": {},
   "source": [
    "Build a default GradientBoostingRegressor and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "23a8659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4049079754601227\n",
      "0.7177914110429447\n"
     ]
    }
   ],
   "source": [
    "gbr1_1 = GradientBoostingRegressor(n_estimators=300)\n",
    "gbr1_1.fit(X_train, y_train)\n",
    "y_pred_gbr1_1 = gbr1_1.predict(X_test)\n",
    "print(accuracy(result(y_pred_gbr1_1), y_test))\n",
    "print(score(y_pred_gbr1_1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf1d0b",
   "metadata": {},
   "source": [
    "The default regressor works better.\n",
    "\n",
    "Look at its feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "98909060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Incorrect_form_ratio</td>\n",
       "      <td>0.365954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>number_of_diff_words</td>\n",
       "      <td>0.183722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>coherence_score</td>\n",
       "      <td>0.038847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>freq_diff_words</td>\n",
       "      <td>0.034135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>freq_of_pronoun</td>\n",
       "      <td>0.022599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ttr</td>\n",
       "      <td>0.019631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lexrank_avg_min_diff</td>\n",
       "      <td>0.018827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_of_words</td>\n",
       "      <td>0.018469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freq_of_wrong_words</td>\n",
       "      <td>0.017976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dale_chall_readability_score</td>\n",
       "      <td>0.017822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>freq_of_distinct_adv</td>\n",
       "      <td>0.017365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>freq_of_noun</td>\n",
       "      <td>0.017044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stopwords_frequency</td>\n",
       "      <td>0.017024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>punctuations</td>\n",
       "      <td>0.015703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>av_word_per_sen</td>\n",
       "      <td>0.015640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>freq_of_transition</td>\n",
       "      <td>0.015291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lexrank_interquartile</td>\n",
       "      <td>0.014932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>verb_to_adv</td>\n",
       "      <td>0.014324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence_complexity</td>\n",
       "      <td>0.012350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>noun_to_adj</td>\n",
       "      <td>0.012080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>freq_of_distinct_adj</td>\n",
       "      <td>0.011651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment_compound</td>\n",
       "      <td>0.011182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>freq_of_adv</td>\n",
       "      <td>0.010814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flesch_reading_ease</td>\n",
       "      <td>0.010119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>0.009997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>phrase_diversity</td>\n",
       "      <td>0.009432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>freq_of_adj</td>\n",
       "      <td>0.009153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freq_of_verb</td>\n",
       "      <td>0.008544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.007622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mcalpine_eflaw</td>\n",
       "      <td>0.007049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_of_grammar_errors</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>text_standard</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flesch_kincaid_grade</td>\n",
       "      <td>0.002753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARI</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_of_short_forms</td>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature name  feature importance\n",
       "17          Incorrect_form_ratio            0.365954\n",
       "23          number_of_diff_words            0.183722\n",
       "26               coherence_score            0.038847\n",
       "24               freq_diff_words            0.034135\n",
       "31               freq_of_pronoun            0.022599\n",
       "25                           ttr            0.019631\n",
       "27          lexrank_avg_min_diff            0.018827\n",
       "0                number_of_words            0.018469\n",
       "11           freq_of_wrong_words            0.017976\n",
       "20  dale_chall_readability_score            0.017822\n",
       "9           freq_of_distinct_adv            0.017365\n",
       "29                  freq_of_noun            0.017044\n",
       "1            stopwords_frequency            0.017024\n",
       "3                   punctuations            0.015703\n",
       "2                av_word_per_sen            0.015640\n",
       "30            freq_of_transition            0.015291\n",
       "28         lexrank_interquartile            0.014932\n",
       "33                   verb_to_adv            0.014324\n",
       "10           sentence_complexity            0.012350\n",
       "32                   noun_to_adj            0.012080\n",
       "8           freq_of_distinct_adj            0.011651\n",
       "12            sentiment_compound            0.011182\n",
       "7                    freq_of_adv            0.010814\n",
       "18           flesch_reading_ease            0.010119\n",
       "14            sentiment_negative            0.009997\n",
       "34              phrase_diversity            0.009432\n",
       "6                    freq_of_adj            0.009153\n",
       "5                   freq_of_verb            0.008544\n",
       "13            sentiment_positive            0.007622\n",
       "22                mcalpine_eflaw            0.007049\n",
       "15         num_of_grammar_errors            0.005338\n",
       "21                 text_standard            0.003258\n",
       "19          flesch_kincaid_grade            0.002753\n",
       "4                            ARI            0.002632\n",
       "16            num_of_short_forms            0.000721"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_gbr1_1 = pd.DataFrame({'feature name': gbr1_1.feature_names_in_, 'feature importance': gbr1_1.feature_importances_})\n",
    "fi_gbr1_1 = fi_gbr1_1.sort_values(by='feature importance',ascending=False)\n",
    "fi_gbr1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f028d27",
   "metadata": {},
   "source": [
    "Extract only the features that have an feature importance value more than 0.01 and build a restricted GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "dbd0efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gbr1_1_res = X_train[fi_gbr1_1[fi_gbr1_1['feature importance'] > 0.01]['feature name'].values]\n",
    "y_train_gbr1_1_res = y_train\n",
    "X_test_gbr1_1_res = X_test[fi_gbr1_1[fi_gbr1_1['feature importance'] > 0.01]['feature name'].values]\n",
    "y_test_gbr1_1_res = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f9063ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4049079754601227\n",
      "0.7290388548057259\n"
     ]
    }
   ],
   "source": [
    "gbr1_1_res = GradientBoostingRegressor()\n",
    "gbr1_1_res.fit(X_train_gbr1_1_res, y_train_gbr1_1_res)\n",
    "y_pred_gbr1_1_res = gbr1_1_res.predict(X_test_gbr1_1_res)\n",
    "print(accuracy(result(y_pred_gbr1_1_res), y_test_gbr1_1_res))\n",
    "print(score(y_pred_gbr1_1_res, y_test_gbr1_1_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c289c0",
   "metadata": {},
   "source": [
    "The approximate accuracy of the restricted regressor improves, as the accuracy remains unchanged. Thus, the restricted regressor performs better and it's retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9ef8f",
   "metadata": {},
   "source": [
    "### 1.4 Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f149e79",
   "metadata": {},
   "source": [
    "Last, we use stacking to combine LinearRegression, KNeighboursRegressor and DecisionTree and predict 'vocabulary'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da92d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models1 = list()\n",
    "base_models1.append(('lr', lr1))\n",
    "base_models1.append(('knn', knn1))\n",
    "base_models1.append(('dt', dt1))\n",
    "\n",
    "meta_learner1 = LinearRegression()\n",
    "sr1 = StackingRegressor(estimators=base_models1, final_estimator=meta_learner1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08dccfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.379225</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.219136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.441336</td>\n",
       "      <td>3.361111</td>\n",
       "      <td>3.313167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.900822</td>\n",
       "      <td>3.194444</td>\n",
       "      <td>2.827621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.119983</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.142578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.368893</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.635385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>2.953055</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>3.182432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>3.156671</td>\n",
       "      <td>3.388889</td>\n",
       "      <td>3.313167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>3.229754</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.313167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>3.564251</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.635385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>2.898930</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>2.827621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     3.379225  3.222222  3.219136\n",
       "1     3.441336  3.361111  3.313167\n",
       "2     2.900822  3.194444  2.827621\n",
       "3     3.119983  3.222222  3.142578\n",
       "4     3.368893  3.111111  3.635385\n",
       "...        ...       ...       ...\n",
       "2928  2.953055  2.944444  3.182432\n",
       "2929  3.156671  3.388889  3.313167\n",
       "2930  3.229754  3.083333  3.313167\n",
       "2931  3.564251  3.500000  3.635385\n",
       "2932  2.898930  2.944444  2.827621\n",
       "\n",
       "[2933 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sr1 = pd.DataFrame([lr1.predict(X_train), knn1.predict(X_train), dt1.predict(X_train)]).T\n",
    "X_train_sr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bf917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "Fitting 5 folds for each of 2842 candidates, totalling 14210 fits\n",
      "0.4100204498977505\n",
      "0.712678936605317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sr1.fit(X_train_sr1, y_train)\n",
    "X_test_sr1 = pd.DataFrame([lr1.predict(X_test), knn1.predict(X_test), dt1.predict(X_test)]).T\n",
    "y_pred_sr1 = sr1.predict(X_test_sr1)\n",
    "print(accuracy(result(y_pred_sr1), y_test))\n",
    "print(score(y_pred_sr1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7ea3d",
   "metadata": {},
   "source": [
    "Among Voting, AdaBoosting, GradientBoosting, and Stacking, Stacking works the best for predicting vocabulary, in terms of the accuracy & approximate accuracy of its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1d048",
   "metadata": {},
   "source": [
    "## 2 Predict Cohesion with Prediction of Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105ab01",
   "metadata": {},
   "source": [
    "### 2.1 Voting\n",
    "\n",
    "We use LinearRegression & DecisionTreeRegressor & KNeighboursRegressor to do a voting and check the accuracy and approximate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6a96f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y2 = df['cohesion']\n",
    "X2 = df.iloc[:, 7:]\n",
    "X2 = X2.drop('corrected_text', axis = 1)\n",
    "\n",
    "X_features_vr2 = pd.DataFrame([lr1.predict(X2), knn1.predict(X2), dt1.predict(X2)]).T\n",
    "y_features_vr2 = sr1.predict(X_features_vr2)\n",
    "X2['vocabulary'] = y_features_vr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c280600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=42)\n",
    "vr2 = VotingRegressor(\n",
    "    estimators=[('linear regressor', lr2), ('decision tree', dt2), ('KNN', knn2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92a6b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3292433537832311\n",
      "0.6257668711656442\n",
      "0.43098159509202455\n"
     ]
    }
   ],
   "source": [
    "vr2.fit(X_train2, y_train2)\n",
    "y_pred_vr2 = vr2.predict(X_test2)\n",
    "print(accuracy(result(y_pred_vr2), y_test2))\n",
    "print(score(y_pred_vr2, y_test2))\n",
    "print(error_rate(result(y_pred_vr2), y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53180e48",
   "metadata": {},
   "source": [
    "### 2.2 AdaBoost\n",
    "\n",
    "Besides, we build a AdaBoostRegressor, whose base estimator would be a DecisionTreeRegressor with optimal parameters got from the training of the single DecisionTreeRegressor dt1, to see the accuracy and approximate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09b4d842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                                       max_depth=3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;,\n",
       "                                                       max_depth=3))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(criterion=&#x27;friedman_mse&#x27;, max_depth=3)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='friedman_mse',\n",
       "                                                       max_depth=3))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar2 = AdaBoostRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(criterion='friedman_mse', max_depth=3, min_samples_split=2)\n",
    ")\n",
    "ar2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c69377de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3261758691206544\n",
      "0.6247443762781186\n"
     ]
    }
   ],
   "source": [
    "y_pred_ar2 = ar2.predict(X_test2)\n",
    "print(accuracy(result(y_pred_ar2), y_test2))\n",
    "print(score(y_pred_ar2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b955fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1386855033),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=768808940),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=14216133),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=305034183),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=258400370),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1345506011),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1961507266),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1025583119),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=187780172),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=717969628),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=812815045),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1089204465),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=8101275),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=475294894),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=529130584),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1743786965),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1878013997),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1612113320),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=578707606),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=609262091),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=126952577),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=469314212),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1654932586),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=760445730),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=22033644),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=441451254),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1775735831),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=759969468),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=111506557),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1659644777),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1177383415),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=477726914),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1626058604),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=928924569),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1151733949),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=122056870),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=220556990),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=524977738),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=840323059),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=486735294),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1748665802),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1533495987),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=2133550986),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=956590726),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1672968513),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=54138577),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1030319178),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=1602465425),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=696477100),\n",
       " DecisionTreeRegressor(criterion='friedman_mse', max_depth=3,\n",
       "                       random_state=880645422)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar2.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "653cf0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13148511, 1.15527328, 0.99949646, 0.72950173, 0.69212107,\n",
       "       0.56420284, 0.30643586, 0.73259716, 0.52768525, 0.71164656,\n",
       "       0.43807635, 0.49079162, 0.25275893, 0.24145393, 0.2908627 ,\n",
       "       0.16899363, 0.30561844, 0.23841934, 0.41869392, 0.31035078,\n",
       "       0.32828247, 0.54342179, 0.41188816, 0.30492591, 0.42249987,\n",
       "       0.3301788 , 0.44621735, 0.2382099 , 0.5227858 , 0.40215741,\n",
       "       0.29305219, 0.41584206, 0.27869237, 0.10790143, 0.56112589,\n",
       "       0.10426728, 0.28257568, 0.48430785, 0.64890477, 0.42217596,\n",
       "       0.40144659, 0.73577359, 0.40300788, 0.43063835, 0.52855413,\n",
       "       0.34840228, 0.63295939, 0.10049314, 0.2813549 , 0.06279304])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar2.estimator_weights_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1980f8",
   "metadata": {},
   "source": [
    "### 2.3 Gradient Boosting\n",
    "\n",
    "We also build a GradientBoostingRegressor, whose base estimator is a DecisionTreeRegressor, and see its accuracy and approximate accuracy.\n",
    "\n",
    "Need to find the best parameters for GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a23a7a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'squared_error', 'learning_rate': 0.1, 'loss': 'absolute_error'}\n",
      "0.31443808963024145\n"
     ]
    }
   ],
   "source": [
    "gbr2 = GradientBoostingRegressor(n_estimators=100)\n",
    "parameters2 = {\n",
    "    'loss':['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'learning_rate':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'criterion':['friedman_mse', 'squared_error', 'mse']\n",
    "}\n",
    "gs_gbr2 = GridSearchCV(gbr1, parameters2)\n",
    "gs_gbr2.fit(X_train2, y_train2)\n",
    "print(gs_gbr2.best_params_)\n",
    "print(gs_gbr2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6caaf713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3220858895705521\n",
      "0.5593047034764826\n"
     ]
    }
   ],
   "source": [
    "gbr2_adj = GradientBoostingRegressor(\n",
    "    criterion = 'squared_error',\n",
    "    learning_rate = 0.1,\n",
    "    loss = 'absolute_error',\n",
    "    n_estimators=100\n",
    ")\n",
    "gbr2_adj.fit(X_train2, y_train2)\n",
    "y_pred_gbr2_adj = gbr2_adj.predict(X_test2)\n",
    "\n",
    "print(accuracy(result(y_pred_gbr2_adj), y_test2))\n",
    "print(score(y_pred_gbr2_adj, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a6857",
   "metadata": {},
   "source": [
    "Build a default GradientBoostingRegressor and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c05628bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3292433537832311\n",
      "0.6349693251533742\n",
      "0.4279141104294479\n"
     ]
    }
   ],
   "source": [
    "gbr2_1 = GradientBoostingRegressor(n_estimators=100)\n",
    "gbr2_1.fit(X_train2, y_train2)\n",
    "y_pred_gbr2_1 = gbr2_1.predict(X_test2)\n",
    "print(accuracy(result(y_pred_gbr2_1), y_test2))\n",
    "print(score(y_pred_gbr2_1, y_test2))\n",
    "print(error_rate(result(y_pred_gbr2_1), y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6708ed",
   "metadata": {},
   "source": [
    "The default regressor works better.\n",
    "\n",
    "Look at its feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ba1734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vocabulary</td>\n",
       "      <td>0.658759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Incorrect_form_ratio</td>\n",
       "      <td>0.032724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>punctuations</td>\n",
       "      <td>0.028944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ttr</td>\n",
       "      <td>0.023088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>av_word_per_sen</td>\n",
       "      <td>0.020179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sentiment_negative</td>\n",
       "      <td>0.015232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentence_complexity</td>\n",
       "      <td>0.013756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>freq_of_pronoun</td>\n",
       "      <td>0.012911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mcalpine_eflaw</td>\n",
       "      <td>0.012702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>freq_of_noun</td>\n",
       "      <td>0.011964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>coherence_score</td>\n",
       "      <td>0.011877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lexrank_interquartile</td>\n",
       "      <td>0.010954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_of_words</td>\n",
       "      <td>0.010891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>freq_of_adj</td>\n",
       "      <td>0.010726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>freq_of_transition</td>\n",
       "      <td>0.009724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stopwords_frequency</td>\n",
       "      <td>0.009665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_of_grammar_errors</td>\n",
       "      <td>0.009530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>freq_of_distinct_adv</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freq_of_verb</td>\n",
       "      <td>0.009405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lexrank_avg_min_diff</td>\n",
       "      <td>0.009383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freq_of_wrong_words</td>\n",
       "      <td>0.008984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sentiment_compound</td>\n",
       "      <td>0.008476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>noun_to_adj</td>\n",
       "      <td>0.006568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>number_of_diff_words</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>verb_to_adv</td>\n",
       "      <td>0.005314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentiment_positive</td>\n",
       "      <td>0.005161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>freq_of_distinct_adj</td>\n",
       "      <td>0.004415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>phrase_diversity</td>\n",
       "      <td>0.004322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>freq_diff_words</td>\n",
       "      <td>0.004203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>freq_of_adv</td>\n",
       "      <td>0.003590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dale_chall_readability_score</td>\n",
       "      <td>0.003212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flesch_reading_ease</td>\n",
       "      <td>0.002177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flesch_kincaid_grade</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>text_standard</td>\n",
       "      <td>0.001655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_of_short_forms</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARI</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature name  feature importance\n",
       "35                    vocabulary            0.658759\n",
       "17          Incorrect_form_ratio            0.032724\n",
       "3                   punctuations            0.028944\n",
       "25                           ttr            0.023088\n",
       "2                av_word_per_sen            0.020179\n",
       "14            sentiment_negative            0.015232\n",
       "10           sentence_complexity            0.013756\n",
       "31               freq_of_pronoun            0.012911\n",
       "22                mcalpine_eflaw            0.012702\n",
       "29                  freq_of_noun            0.011964\n",
       "26               coherence_score            0.011877\n",
       "28         lexrank_interquartile            0.010954\n",
       "0                number_of_words            0.010891\n",
       "6                    freq_of_adj            0.010726\n",
       "30            freq_of_transition            0.009724\n",
       "1            stopwords_frequency            0.009665\n",
       "15         num_of_grammar_errors            0.009530\n",
       "9           freq_of_distinct_adv            0.009479\n",
       "5                   freq_of_verb            0.009405\n",
       "27          lexrank_avg_min_diff            0.009383\n",
       "11           freq_of_wrong_words            0.008984\n",
       "12            sentiment_compound            0.008476\n",
       "32                   noun_to_adj            0.006568\n",
       "23          number_of_diff_words            0.006400\n",
       "33                   verb_to_adv            0.005314\n",
       "13            sentiment_positive            0.005161\n",
       "8           freq_of_distinct_adj            0.004415\n",
       "34              phrase_diversity            0.004322\n",
       "24               freq_diff_words            0.004203\n",
       "7                    freq_of_adv            0.003590\n",
       "20  dale_chall_readability_score            0.003212\n",
       "18           flesch_reading_ease            0.002177\n",
       "19          flesch_kincaid_grade            0.002135\n",
       "21                 text_standard            0.001655\n",
       "16            num_of_short_forms            0.001122\n",
       "4                            ARI            0.000371"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_gbr2_1 = pd.DataFrame({'feature name': gbr2_1.feature_names_in_, 'feature importance': gbr2_1.feature_importances_})\n",
    "fi_gbr2_1 = fi_gbr2_1.sort_values(by='feature importance',ascending=False)\n",
    "fi_gbr2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b51913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gbr2_1_res = X_train2[fi_gbr2_1[fi_gbr2_1['feature importance'] > 0.01]['feature name'].values]\n",
    "y_train_gbr2_1_res = y_train2\n",
    "X_test_gbr2_1_res = X_test2[fi_gbr2_1[fi_gbr2_1['feature importance'] > 0.01]['feature name'].values]\n",
    "y_test_gbr2_1_res = y_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222d15e",
   "metadata": {},
   "source": [
    "Extract only the features that have an feature importance value more than 0.01 and build a restricted GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "130695d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33026584867075665\n",
      "0.6400817995910021\n",
      "0.4284253578732106\n"
     ]
    }
   ],
   "source": [
    "gbr2_1_res = GradientBoostingRegressor()\n",
    "gbr2_1_res.fit(X_train_gbr2_1_res, y_train_gbr2_1_res)\n",
    "y_pred_gbr2_1_res = gbr2_1_res.predict(X_test_gbr2_1_res)\n",
    "print(accuracy(result(y_pred_gbr2_1_res), y_test_gbr2_1_res))\n",
    "print(score(y_pred_gbr2_1_res, y_test_gbr2_1_res))\n",
    "print(error_rate(result(y_pred_gbr2_1_res), y_test_gbr2_1_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7e4a4",
   "metadata": {},
   "source": [
    "Both the accuracy and approximate accuracy of the restricted regressor improves, as the accuracy remains unchanged. Thus, the restricted regressor performs better and it's retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72faeb2e",
   "metadata": {},
   "source": [
    "### 2.4 Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe3634",
   "metadata": {},
   "source": [
    "Last, we use stacking to combine LinearRegression, KNeighboursRegressor and DecisionTree and predict 'cohesion'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "281ca3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models2 = list()\n",
    "base_models2.append(('lr', lr2))\n",
    "base_models2.append(('knn', knn2))\n",
    "base_models2.append(('dt', dt2))\n",
    "\n",
    "meta_learner2 = LinearRegression()\n",
    "sr2 = StackingRegressor(estimators=base_models2, final_estimator=meta_learner2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfdf1a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298237</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.178481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.251153</td>\n",
       "      <td>3.194444</td>\n",
       "      <td>3.499154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.971255</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>2.744887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.042594</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.178481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.070328</td>\n",
       "      <td>3.194444</td>\n",
       "      <td>3.005362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>2.813369</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>2.744887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>3.208429</td>\n",
       "      <td>3.527778</td>\n",
       "      <td>3.178481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>3.207558</td>\n",
       "      <td>3.027778</td>\n",
       "      <td>3.178481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>3.491453</td>\n",
       "      <td>3.527778</td>\n",
       "      <td>3.499154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>2.977704</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.744887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2\n",
       "0     3.298237  3.166667  3.178481\n",
       "1     3.251153  3.194444  3.499154\n",
       "2     2.971255  3.111111  2.744887\n",
       "3     3.042594  3.000000  3.178481\n",
       "4     3.070328  3.194444  3.005362\n",
       "...        ...       ...       ...\n",
       "2928  2.813369  2.888889  2.744887\n",
       "2929  3.208429  3.527778  3.178481\n",
       "2930  3.207558  3.027778  3.178481\n",
       "2931  3.491453  3.527778  3.499154\n",
       "2932  2.977704  2.777778  2.744887\n",
       "\n",
       "[2933 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sr2 = pd.DataFrame([lr2.predict(X_train2), knn2.predict(X_train2), dt2.predict(X_train2)]).T\n",
    "X_train_sr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "72dae211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31901840490797545\n",
      "0.6206543967280164\n",
      "0.4396728016359918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but DecisionTreeRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sr2.fit(X_train_sr2, y_train2)\n",
    "X_test_sr2 = pd.DataFrame([lr2.predict(X_test2), knn2.predict(X_test2), dt2.predict(X_test2)]).T\n",
    "y_pred_sr2 = sr2.predict(X_test_sr2)\n",
    "print(accuracy(result(y_pred_sr2), y_test2))\n",
    "print(score(y_pred_sr2, y_test2))\n",
    "print(error_rate(result(y_pred_sr2), y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f01d01",
   "metadata": {},
   "source": [
    "Among Voting, AdaBoosting, GradientBoosting, and Stacking, GradientBoosting with restricted features whose feature importance is more than 0.01 works the best for predicting cohesion, considering the combination of accuracy & approximate accuracy & error rate of its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862c288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "070eb8febb0d65b63a678342faa3921edb1fc763d0e6db793e5b6232b3f5c5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
