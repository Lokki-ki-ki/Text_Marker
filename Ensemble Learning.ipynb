{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896c80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f647bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be37af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(predictions):\n",
    "    predictions = predictions.tolist()\n",
    "    result_list=[]\n",
    "    for pred in predictions:\n",
    "        result = pred // 0.5 * 0.5\n",
    "        if (pred - result) > 0.25:\n",
    "            result += 0.5\n",
    "        if result < 1.0:\n",
    "            result = 1.0\n",
    "        if result > 5.0:\n",
    "            result = 5.0\n",
    "        result_list.append(result)\n",
    "    return result_list\n",
    "\n",
    "# Accuracy score\n",
    "def accuracy(Ypred, Ytrue):\n",
    "    Ytrue = Ytrue.tolist()\n",
    "    accurate = 0\n",
    "    for i in range(len(Ytrue)):\n",
    "        if Ytrue[i] == Ypred[i]:\n",
    "            accurate += 1\n",
    "    return accurate / len(Ytrue)\n",
    "\n",
    "# approximate accurancy rate\n",
    "def score(pred, test):\n",
    "    test = test.tolist()\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        p = pred[i]\n",
    "        t = test[i]\n",
    "        if p < t+0.5 and p > t-0.5:\n",
    "            correct += 1\n",
    "    return correct / len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3964f",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d0f00",
   "metadata": {},
   "source": [
    "linear reg = lr1, lr2\n",
    "decision tree = dt1, dt2\n",
    "neural network = nn1, nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465d1cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.24.1 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://8e257b59-34f3-4dc6-8da4-24326c9ea20e/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\12560\\OneDrive - National University of Singapore\\Documents\\GitHub\\Text_Marker\\Ensemble Learning.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12560/OneDrive%20-%20National%20University%20of%20Singapore/Documents/GitHub/Text_Marker/Ensemble%20Learning.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dt2 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDecision_Tree_cohesion.sav\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/12560/OneDrive%20-%20National%20University%20of%20Singapore/Documents/GitHub/Text_Marker/Ensemble%20Learning.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#nn1 = pickle.load(open(\"neural_network_vocab.sav\", 'rb'))\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/12560/OneDrive%20-%20National%20University%20of%20Singapore/Documents/GitHub/Text_Marker/Ensemble%20Learning.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m nn2 \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mnn_model_cohesion.sav\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\keras\\saving\\pickle_utils.py:47\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(dest_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     46\u001b[0m                 f\u001b[39m.\u001b[39mwrite(archive\u001b[39m.\u001b[39mextractfile(name)\u001b[39m.\u001b[39mread())\n\u001b[1;32m---> 47\u001b[0m model \u001b[39m=\u001b[39m save_module\u001b[39m.\u001b[39;49mload_model(temp_dir)\n\u001b[0;32m     48\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\12560\\anaconda3\\envs\\BT4222\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:933\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    930\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 933\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    938\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    939\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://8e257b59-34f3-4dc6-8da4-24326c9ea20e/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "lr1 = pickle.load(open(\"lr.sav\", 'rb'))\n",
    "lr2 = pickle.load(open(\"lr_second.sav\", 'rb'))\n",
    "dt1 = pickle.load(open(\"Decision_Tree_vocab.sav\", 'rb'))\n",
    "dt2 = pickle.load(open(\"Decision_Tree_cohesion.sav\", 'rb'))\n",
    "nn1 = pickle.load(open(\"neural_network_vocab.sav\", 'rb'))\n",
    "nn2 = pickle.load(open(\"nn_model_cohesion.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30890b",
   "metadata": {},
   "source": [
    "## 1 Predict Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Processed_Data.csv\")\n",
    "y = df['vocabulary']\n",
    "X = df.iloc[:, 7:]\n",
    "X = X.drop('corrected_text', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa1d5a",
   "metadata": {},
   "source": [
    "### 1.1 Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e9d1a",
   "metadata": {},
   "source": [
    "linear regression:\n",
    "exact accuracy = 0.3987730061349693\n",
    "approximate accuracy = \n",
    "\n",
    "decision tree:\n",
    "exact accuracy = 0.4061302681992337\n",
    "approximate accuracy = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ac223",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "vr = VotingRegressor(\n",
    "    estimators=[('linear regressor', lr1), ('decision tree', dt1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472864cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3895705521472393\n",
      "0.7290388548057259\n"
     ]
    }
   ],
   "source": [
    "vr.fit(X_train, y_train)\n",
    "y_pred1 = vr.predict(X_test)\n",
    "print(accuracy(result(y_pred1), y_test))\n",
    "print(score(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962af4f3",
   "metadata": {},
   "source": [
    "### 1.2 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1466ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adc9ef8f",
   "metadata": {},
   "source": [
    "### 1.3 Stacking\n",
    "\n",
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da92d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a1d048",
   "metadata": {},
   "source": [
    "## 2 Predict Cohesion with Prediction of Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105ab01",
   "metadata": {},
   "source": [
    "### 2.1 Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53180e48",
   "metadata": {},
   "source": [
    "### 2.2 AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72faeb2e",
   "metadata": {},
   "source": [
    "### 2.3 Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ca3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('BT4222')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "070eb8febb0d65b63a678342faa3921edb1fc763d0e6db793e5b6232b3f5c5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
